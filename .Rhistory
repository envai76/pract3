self$dropout1() %>%
torch_flatten(start_dim = 2) %>%           # N * 64 * 110 * 110 --> N * 774400
self$fc1() %>%                             # N * 128
nnf_relu() %>%
self$dropout2() %>%
self$fc2()                                 # N * 2 (change the output size to match your classification task)
}
)
# Set the number of epochs
num_epochs <- 3
train_loss <- numeric(num_epochs)
train_acc <- numeric(num_epochs)
test_loss <- numeric(num_epochs)
test_acc <- numeric(num_epochs)
# Loop through the epochs
for (epoch in 1:num_epochs) {
# Perform training and validation for each epoch
fitted <- net %>%
setup(
loss = nn_cross_entropy_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
fit(train_dataloader, epochs = 1, valid_data = test_dataloader)
# Print the metrics for the current epoch
cat("Epoch ", epoch, "/", num_epochs, "\n")
cat("Train metrics: Loss: ", fitted$records$metrics$train[[1]]$loss, " - Acc: ", fitted$records$metrics$train[[1]]$acc, "\n")
cat("Valid metrics: Loss: ", fitted$records$metrics$valid[[1]]$loss, " - Acc: ", fitted$records$metrics$valid[[1]]$acc, "\n")
cat("\n")
# Store the loss and accuracy values
train_loss[epoch] <- fitted$records$metrics$train[[1]]$loss
train_acc[epoch] <- fitted$records$metrics$train[[1]]$acc
test_loss[epoch] <- fitted$records$metrics$train[[1]]$loss
test_acc[epoch] <- fitted$records$metrics$valid[[1]]$acc
}
dim(train_X)
train_X <- aperm(train_X, c(1,4,2,3))
test_X <- aperm(test_X, c(1,4,2,3))
val_X <- aperm(val_X,c(1,4,2,3))
dim(train_X)
# Load the torch package
library(torch)
library(torchvision)
library(luz)
# Define a custom dataset class
ImageDataset <- dataset(
name = "ImageDataset",
initialize = function(X, y) {
# Store the data as tensors
self$data <- torch_tensor(X)
self$labels <- torch_tensor(y)
},
.getitem = function(i) {
# Return a single sample and label
x <- self$data[i,,,]
y <- self$labels[i]
list(x = x, y = y)
},
.length = function() {
# Return the number of samples
dim(self$data)[1]
}
)
# Create a dataset object from your data
train_dataset <- ImageDataset(train_X, train_y)
test_dataset <- ImageDataset(test_X, test_y)
val_dataset <- ImageDataset(val_X, val_y)
# Create a dataloader object from your dataset
train_dataloader <- dataloader(train_dataset, batch_size = 16)
test_dataloader <- dataloader(test_dataset, batch_size = 16)
val_dataloader <- dataloader(val_dataset, batch_size = 16)
# Iterate over batches of data
batch = train_dataloader$.iter()$.next()
# Visualize the first batch size
batch[[1]]$size()
net <- nn_module(
"Net",
initialize = function() {
self$conv1 <- nn_conv2d(1, 32, 3, 1)
self$conv2 <- nn_conv2d(32, 64, 3, 1)
self$dropout1 <- nn_dropout2d(0.25)
self$dropout2 <- nn_dropout2d(0.5)
self$fc1 <- nn_linear(774400, 128)  # Adjust the input size based on your image dimensions
self$fc2 <- nn_linear(128, 2)             # Change the output size to match your classification task
},
forward = function(x) {
x %>%                                        # N * 1 * 224 * 224
self$conv1() %>%                           # N * 32 * 222 * 222
nnf_relu() %>%
self$conv2() %>%                           # N * 64 * 220 * 220
nnf_relu() %>%
nnf_max_pool2d(2) %>%                      # N * 64 * 110 * 110
self$dropout1() %>%
torch_flatten(start_dim = 2) %>%           # N * 64 * 110 * 110 --> N * 774400
self$fc1() %>%                             # N * 128
nnf_relu() %>%
self$dropout2() %>%
self$fc2()                                 # N * 2 (change the output size to match your classification task)
}
)
# Set the number of epochs
num_epochs <- 3
train_loss <- numeric(num_epochs)
train_acc <- numeric(num_epochs)
test_loss <- numeric(num_epochs)
test_acc <- numeric(num_epochs)
# Loop through the epochs
for (epoch in 1:num_epochs) {
# Perform training and validation for each epoch
fitted <- net %>%
setup(
loss = nn_cross_entropy_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
fit(train_dataloader, epochs = 1, valid_data = test_dataloader)
# Print the metrics for the current epoch
cat("Epoch ", epoch, "/", num_epochs, "\n")
cat("Train metrics: Loss: ", fitted$records$metrics$train[[1]]$loss, " - Acc: ", fitted$records$metrics$train[[1]]$acc, "\n")
cat("Valid metrics: Loss: ", fitted$records$metrics$valid[[1]]$loss, " - Acc: ", fitted$records$metrics$valid[[1]]$acc, "\n")
cat("\n")
# Store the loss and accuracy values
train_loss[epoch] <- fitted$records$metrics$train[[1]]$loss
train_acc[epoch] <- fitted$records$metrics$train[[1]]$acc
test_loss[epoch] <- fitted$records$metrics$train[[1]]$loss
test_acc[epoch] <- fitted$records$metrics$valid[[1]]$acc
}
knitr::opts_chunk$set(echo = TRUE)
install_torch()
install_torch()
install.packages("torch")
# Install necessary packages
#install.packages("gridExtra")
#install.packages("jpeg")
#install.packages("imager")
#install.packages("magick")
# Install Bioconductor package (if not already installed)
#if (!require("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
# Install EBImage package from Bioconductor
#BiocManager::install("EBImage")
#install.packages("abind")
# Install torch, torchvision, and luz
#install.packages("torch")
#install.packages("torchvision")
#install.packages("luz")
install.packages("torch")
torch::install_torch()
# Install necessary packages
#install.packages("gridExtra")
#install.packages("jpeg")
#install.packages("imager")
#install.packages("magick")
# Install Bioconductor package (if not already installed)
#if (!require("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
# Install EBImage package from Bioconductor
#BiocManager::install("EBImage")
#install.packages("abind")
# Install torch, torchvision, and luz
#install.packages("torch")
#install.packages("torchvision")
#install.packages("luz")
knitr::opts_chunk$set(echo = TRUE)
torch:::lantern_available()
# Load the torch package
library(torch)
library(torchvision)
library(luz)
torch:::lantern_available()
# Load the torch package
library(torch)
library(torchvision)
library(luz)
library(lantern)
# install.packages("torch")
# torch::install_torch()
install.packages('lantern')
# Install necessary packages
#install.packages("gridExtra")
#install.packages("jpeg")
#install.packages("imager")
#install.packages("magick")
# Install Bioconductor package (if not already installed)
#if (!require("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
# Install EBImage package from Bioconductor
#BiocManager::install("EBImage")
#install.packages("abind")
# Install torch, torchvision, and luz
#install.packages("torch")
#install.packages("torchvision")
#install.packages("luz")
R.version.string
R.version.string
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
# knitr::opts_chunk$set(echo = TRUE)
# load packages
library(ggplot2)
install.packages("torch")
torch::install_torch()
# Install necessary packages
install.packages("gridExtra")
install.packages("jpeg")
install.packages("imager")
install.packages("magick")
# Install Bioconductor package (if not already installed)
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
# Install EBImage package from Bioconductor
BiocManager::install("EBImage")
install.packages("abind")
# Install torch, torchvision, and luz
install.packages("torch")
install.packages("torchvision")
# knitr::opts_chunk$set(echo = TRUE)
# load packages
library(ggplot2)
# knitr::opts_chunk$set(echo = TRUE)
# load packages
library(ggplot2)
library(gridExtra)
library(imager)
library(jpeg)
library(magick)
library(EBImage)
library(grid)
library(dplyr)
library(abind)
# install.packages("torch")
# torch::install_torch()
# Install necessary packages
# install.packages("gridExtra")
# install.packages("jpeg")
# install.packages("imager")
# install.packages("magick")
# Install Bioconductor package (if not already installed)
# if (!require("BiocManager", quietly = TRUE))
# install.packages("BiocManager")
# Install EBImage package from Bioconductor
# BiocManager::install("EBImage")
# install.packages("abind")
# Install torch, torchvision, and luz
# install.packages("torch")
install.packages("torchvision")
install.packages("luz")
train_X <- aperm(train_X, c(1,4,2,3))
# Load the torch package
library(torch)
library(torchvision)
# Load the torch package
library(torch)
library(luz)
# knitr::opts_chunk$set(echo = TRUE)
# Load the torch package
library(torch)
library(torchvision)
# Load the torch package
library(torch)
library(torchvision)
# Load the torch package
# library(torch)
# library(torchvision)
library(luz)
# Load the torch package
# library(torch)
# library(torchvision)
# library(luz)
library(lantern)
knitr::opts_chunk$set(echo = TRUE)
# load packages
library(ggplot2)
library(gridExtra)
library(imager)
library(jpeg)
library(magick)
library(EBImage)
library(grid)
library(dplyr)
library(abind)
data_folder = "data/lab3_chest_xray"
files <- list.files(data_folder, full.names=TRUE, recursive=TRUE)
sort(sample(files, 20))
# Exploring dataset
base_dir <- "data/lab3_chest_xray"
train_pneumonia_dir <- file.path(base_dir, "train", "PNEUMONIA")
train_normal_dir <- file.path(base_dir, "train", "NORMAL")
test_pneumonia_dir <- file.path(base_dir, "test", "PNEUMONIA")
test_normal_dir <- file.path(base_dir, "test", "NORMAL")
val_normal_dir <- file.path(base_dir, "validate", "NORMAL")
val_pneumonia_dir <- file.path(base_dir, "validate", "PNEUMONIA")
train_pn <- list.files(train_pneumonia_dir, full.names = TRUE)
train_normal <- list.files(train_normal_dir, full.names = TRUE)
test_normal <- list.files(test_normal_dir, full.names = TRUE)
test_pn <- list.files(test_pneumonia_dir, full.names = TRUE)
val_pn <- list.files(val_pneumonia_dir, full.names = TRUE)
val_normal <- list.files(val_normal_dir, full.names = TRUE)
cat("Total Images:", length(c(train_pn, train_normal, test_normal, test_pn, val_pn, val_normal)), "\n")
cat("Total Pneumonia Images:", length(c(train_pn, test_pn, val_pn)), "\n")
cat("Total Normal Images:", length(c(train_normal, test_normal, val_normal)), "\n")
train_dataset <- c(train_pn, train_normal)
train_labels <- c(rep("pneumonia", length(train_pn)), rep("normal", length(train_normal)))
test_dataset <- c(test_pn, test_normal)
test_labels <- c(rep("pneumonia", length(test_pn)), rep("normal", length(test_normal)))
val_dataset <- c(val_pn, val_normal)
val_labels <- c(rep("pneumonia", length(val_pn)), rep("normal", length(val_normal)))
# Create a data frame with the dataset and labels
train_data <- data.frame(dataset = train_dataset, label = train_labels)
test_data <- data.frame(dataset = test_dataset, label = test_labels)
val_data <- data.frame(dataset = val_dataset, label = val_labels)
# Shuffle the data frame
train_data <- train_data[sample(nrow(train_data)), ]
test_data <- test_data[sample(nrow(test_data)), ]
val_data <- val_data[sample(nrow(val_data)), ]
# Extract the shuffled dataset and labels
shuffled_train_dataset <- train_data$dataset
shuffled_train_labels <- train_data$label
shuffled_test_dataset <- test_data$dataset
shuffled_test_labels <- test_data$label
shuffled_val_dataset <- val_data$dataset
shuffled_val_labels <- val_data$label
#showing a file name from test set
cat("finle name: ", shuffled_train_dataset[5], "\nlabel: ", shuffled_train_labels[5])
# Create a list to store the ggplot objects
plots <- list()
# Iterate through the images and labels
for (i in 1:4) {
image <- readImage(shuffled_train_dataset[i])
# Create a ggplot object for the image with the corresponding label
plot <- ggplot() +
theme_void() +
annotation_custom(
rasterGrob(image, interpolate = TRUE),
xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf
)
# Add the ggplot object to the list
plots[[i]] <- plot
}
# Arrange the plots in a 2x2 grid
grid.arrange(grobs = plots, nrow = 2, ncol = 2)
process_images <- function(shuffled_dataset) {
img_size <- 224  # Desired image size
# Initialize an empty list to store processed images
X <- list()
# Loop through each image path in shuffled_train_dataset
for (image_path in shuffled_dataset) {
# Read the image
img <- imager::load.image(image_path)
# Normalize the image
img_normalized <- img / 255
# Resize the image
img_resized <- resize(img_normalized, img_size, img_size)
# Append the processed image to the list
X <- c(X, list(img_resized))
}
return(X)
}
train_X <- process_images(shuffled_train_dataset)
# Install torch, torchvision, and luz
# install.packages("torch")
# install.packages("torchvision")
# install.packages("luz")
install.packages("luz", repos = "https://cran.rstudio.com/")
# Install torch, torchvision, and luz
# install.packages("torch")
# install.packages("torchvision")
# install.packages("luz")
# install.packages("luz", repos = "https://cran.rstudio.com/")
install.packages("torchvision", repos = "https://cran.rstudio.com/")
# Load the torch package
library(torch)
library(torchvision)
# Load the torch package
library(torch)
# library(torchvision)
library(luz)
# Load the torch package
library(torch)
# library(torchvision)
library(luz)
# Load the torch package
library(torch)
install.packages("luz", repos = "https://cran.rstudio.com/", type = "source")
# library(torchvision)
library(luz)
install.packages("remotes")
# Load the torch package
library(torch)
install.packages("remotes")
library(remotes)
install_github("autumnai/lantern")
install.packages("luz", repos = "https://cran.rstudio.com/", type = "source")
knitr::opts_chunk$set(echo = TRUE)
# load packages
library(ggplot2)
library(torch)
library(torchvision)
library(luz)
library(gridExtra)
library(imager)
library(jpeg)
library(magick)
library(EBImage)
library(grid)
library(dplyr)
library(abind)
h")
torch:::install_torch()
rch")
install.packages("torch")
torch::install_torch()
knitr::opts_chunk$set(echo = TRUE)
torch::install_torch()
# install.packages("torchvision")
install.packages("luz")
library(luz)
library(luz)
# load packages
library(ggplot2)
library(torch)
library(torchvision)
library(luz)
library(gridExtra)
library(imager)
library(jpeg)
library(magick)
library(EBImage)
library(grid)
library(dplyr)
library(abind)
# Define a custom dataset class
ImageDataset <- dataset(
name = "ImageDataset",
initialize = function(X, y) {
# Store the data as tensors
self$data <- torch_tensor(X)
self$labels <- torch_tensor(y)
},
.getitem = function(i) {
# Return a single sample and label
x <- self$data[i,,,]
y <- self$labels[i]
list(x = x, y = y)
},
.length = function() {
# Return the number of samples
dim(self$data)[1]
}
)
# Create a dataset object from your data
train_dataset <- ImageDataset(train_X, train_y)
knitr::opts_chunk$set(echo = TRUE)
# load packages
library(ggplot2)
library(torch)
library(torchvision)
library(luz)
library(gridExtra)
library(imager)
library(jpeg)
library(magick)
library(EBImage)
library(grid)
library(dplyr)
library(abind)
install.packages("torch")
torch::install_torch()
knitr::opts_chunk$set(echo = TRUE)
install.packages("torch")
torch::install_torch()
install.packages("torch")
install.packages("torchvision")
install.packages("torchvision")
install.packages("luz")
# load packages
library(ggplot2)
library(torch)
library(torchvision)
library(luz)
library(gridExtra)
library(imager)
library(jpeg)
library(magick)
library(EBImage)
library(grid)
library(dplyr)
library(abind)
# Install torch, torchvision, and luz
# install.packages("torch")
# torch::install_torch()
# install.packages("torchvision")
# install.packages("luz")
install.packages("luz", repos = "https://cran.rstudio.com/")
install.packages("luz", repos = "https://cran.rstudio.com/")
install.packages("torchvision", repos = "https://cran.rstudio.com/")
install.packages("torchvision", repos = "https://cran.rstudio.com/")
library(torch)
install_torch()
library(torch)
install_torch()
install_torch()
knitr::opts_chunk$set(echo = TRUE)
library(torch)
install_torch()
install.packages('lantern')
torch::install_torch()
install_torch()
